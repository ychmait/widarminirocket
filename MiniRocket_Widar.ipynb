{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cNA7cGamHP6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "7c0dd334-2b15-4271-8530-1b089edca2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-646cf6539761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/ECE496/BVP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/ECE496/BVP'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('/content/drive/My Drive/ECE496/BVP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9EqYf1vHa9W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.io as scio\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sktime.transformations.panel.rocket import MiniRocketMultivariate #MiniRocket, MiniRocketMultivariate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Local/Global Gesture ID Translation**"
      ],
      "metadata": {
        "id": "qI5dz2u2BY8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "room_dict = {'20181121':1,\n",
        "'20181109':1,\n",
        "'20181112':1,\n",
        "'20181115':1,\n",
        "'20181116':1,\n",
        "'20181117':2,\n",
        "'20181118':2,\n",
        "'20181121':1,\n",
        "'20181127':2,\n",
        "'20181128':2,\n",
        "'20181130':1,\n",
        "'20181204':2,\n",
        "'20181205':2,\n",
        "'20181208':2,\n",
        "'20181209':2,\n",
        "'20181211':3\n",
        "}\n",
        "\n",
        "gesture_local_dict = {'20181121':{'1': 'Slide', '2': 'Draw-O(Horizontal)', '3': 'Draw-Zigzag(Horizontal)','4': 'Draw-N(Horizontal)', '5': 'Draw-Triangle(Horizontal)', '6': 'Draw-Rectangle(Horizontal)'},\n",
        "'20181109':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Slide', '5': 'Draw-Zigzag(Vertical)', '6': 'Draw-N(Vertical)'},\n",
        "'20181112':{'1': 'Draw-1', '2': 'Draw-2', '3': 'Draw-3', '4': 'Draw-4', '5': 'Draw-5', '6': 'Draw-6', '7': 'Draw-7', '8': 'Draw-8', '9': 'Draw-9', '10': 'Draw-0'},\n",
        "'20181115':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Draw-O(Vertical)', '5': 'Draw-Zigzag(Vertical)', '6': 'Draw-N(Vertical)',},\n",
        "'20181116':{'1': 'Draw-1', '2': 'Draw-2', '3': 'Draw-3', '4': 'Draw-4', '5': 'Draw-5', '6': 'Draw-6', '7': 'Draw-7', '8': 'Draw-8', '9': 'Draw-9', '10': 'Draw-0'},\n",
        "'20181117':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Draw-O(Vertical)', '5': 'Draw-Zigzag(Vertical)', '6': 'Draw-N(Vertical)'},\n",
        "'20181118':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Draw-O(Vertical)', '5': 'Draw-Zigzag(Vertical)', '6': 'Draw-N(Vertical)'},\n",
        "'20181121':{'1': 'Slide', '2': 'Draw-O(Horizontal)', '3': 'Draw-Zigzag(Horizontal)', '4': 'Draw-N(Horizontal)', '5': 'Draw-Triangle(Horizontal)', '6': 'Draw-Rectangle(Horizontal)'},\n",
        "'20181127':{'1': 'Slide', '2': 'Draw-O(Horizontal)', '3': 'Draw-Zigzag(Horizontal)', '4': 'Draw-N(Horizontal)', '5': 'Draw-Triangle(Horizontal)', '6': 'Draw-Rectangle(Horizontal)'},\n",
        "'20181128':{'1':'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Draw-O(Horizontal)', '5': 'Draw-Zigzag(Horizontal)', '6': 'Draw-N(Horizontal)'},\n",
        "'20181130':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Slide', '5': 'Draw-O(Horizontal)', '6': 'Draw-Zigzag(Horizontal)', '7': 'Draw-N(Horizontal)', '8': 'Draw-Triangle(Horizontal)', '9': 'Draw-Rectangle(Horizontal)'},\n",
        "'20181204':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Slide','5': 'Draw-O(Horizontal)', '6': 'Draw-Zigzag(Horizontal)','7': 'Draw-N(Horizontal)', '8': 'Draw-Triangle(Horizontal)', '9': 'Draw-Rectangle(Horizontal)'},\n",
        "'20181205':{'2':{'1': 'Draw-O(Horizontal)', '2': 'Draw-Zigzag(Horizontal)','3': 'Draw-N(Horizontal)', '4': 'Draw-Triangle(Horizontal)','5': 'Draw-Rectangle(Horizontal)'},'3':{'1': 'Slide', '2': 'Draw-O(Horizontal)', '3': 'Draw-Zigzag(Horizontal)', '4': 'Draw-N(Horizontal)', '5': 'Draw-Triangle(Horizontal)', '6': 'Draw-Rectangle(Horizontal)'}},\n",
        "'20181208':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Slide'},\n",
        "'20181209':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Slide', '5': 'Draw-O(Horizontal)', '6': 'Draw-Zigzag(Horizontal)'},\n",
        "'20181211':{'1': 'Push&Pull', '2': 'Sweep', '3': 'Clap', '4': 'Slide', '5': 'Draw-O(Horizontal)', '6': 'Draw-Zigzag(Horizontal)'}\n",
        "}\n",
        "\n",
        "gesture_global_dict = {'Push&Pull': '1' ,\n",
        "'Sweep': '2',\n",
        "'Clap': '3',\n",
        "'Slide': '4',\n",
        "'Draw-N(Horizontal)':'5',\n",
        "'Draw-O(Horizontal)':'6',\n",
        "'Draw-Rectangle(Horizontal)':'7',\n",
        "'Draw-Triangle(Horizontal)':'8',\n",
        "'Draw-Zigzag(Horizontal)':'9',\n",
        "'Draw-Zigzag(Vertical)':'10',\n",
        "'Draw-N(Vertical)':'11',\n",
        "'Draw-O(Vertical)':'12',\n",
        "'Draw-1':'13',\n",
        "'Draw-2':'14',\n",
        "'Draw-3':'15',\n",
        "'Draw-4':'16',\n",
        "'Draw-5':'17',\n",
        "'Draw-6':'18',\n",
        "'Draw-7':'19',\n",
        "'Draw-8':'20',\n",
        "'Draw-9':'21',\n",
        "'Draw-0':'22'}"
      ],
      "metadata": {
        "id": "tSmBVRh041gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Widar Data Functions**"
      ],
      "metadata": {
        "id": "3uynqxFr-bER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L762h96xMjPK",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "#Adapted from Widar3.0 code\n",
        "\n",
        "def normalize_data(data_1):\n",
        "    # data(ndarray)=>data_norm(ndarray): [20,20,T]=>[20,20,T]\n",
        "    data_1_max = np.concatenate((data_1.max(axis=0),data_1.max(axis=1)),axis=0).max(axis=0)\n",
        "    data_1_min = np.concatenate((data_1.min(axis=0),data_1.min(axis=1)),axis=0).min(axis=0)\n",
        "    if (len(np.where((data_1_max - data_1_min) == 0)[0]) > 0):\n",
        "        return data_1\n",
        "    data_1_max_rep = np.tile(data_1_max,(data_1.shape[0],data_1.shape[1],1))\n",
        "    data_1_min_rep = np.tile(data_1_min,(data_1.shape[0],data_1.shape[1],1))\n",
        "    data_1_norm = (data_1 - data_1_min_rep) / (data_1_max_rep - data_1_min_rep)\n",
        "    return  data_1_norm\n",
        "\n",
        "def zero_padding(data, T_MAX):\n",
        "    # data(list)=>data_pad(ndarray): [20,20,T1/T2/...]=>[20,20,T_MAX]\n",
        "    data_pad = []\n",
        "    for i in range(len(data)):\n",
        "        t = np.array(data[i]).shape[2]\n",
        "        data_pad.append(np.pad(data[i], ((0,0),(0,0),(T_MAX - t,0)), 'constant', constant_values = 0).tolist())\n",
        "    return np.array(data_pad)\n",
        "\n",
        "def load_data(path_to_data, motion_sel):\n",
        "    global T_MAX\n",
        "    data = []\n",
        "    label = []\n",
        "    T_MAX=0\n",
        "    \n",
        "    for data_root, data_dirs, data_files in os.walk(path_to_data):\n",
        "        for data_file_name in data_files:\n",
        "            file_path = os.path.join(data_root,data_file_name)\n",
        "            try:\n",
        "                data_1 = scio.loadmat(file_path)['velocity_spectrum_ro']\n",
        "                label_1_local = int(data_file_name.split('-')[2])\n",
        "                location = int(data_file_name.split('-')[3])\n",
        "                orientation = int(data_file_name.split('-')[4])\n",
        "                repetition = int(data_file_name.split('-')[5])\n",
        "\n",
        "                folder_source= str(  str(file_path.split('/')[2]).split('-')[0]  )\n",
        "                #print(\"Source Folder:\" + folder_source)\n",
        "\n",
        "                gesture_name= gesture_local_dict[folder_source][str(label_1_local)]\n",
        "                label_1_global= int (gesture_global_dict[gesture_name])\n",
        "                # Select Motion\n",
        "                if (label_1_global not in motion_sel):\n",
        "                    continue\n",
        "\n",
        "                print('----------------------------------')\n",
        "                print(\"File: \",file_path)\n",
        "                print(\"Gesture name:\", gesture_name)\n",
        "                print(\"Local label:\", label_1_local)\n",
        "                print(\"Global label:\", label_1_global)\n",
        "                # Select Location\n",
        "                # if (location not in [1,2,3,5]):\n",
        "                #     continue\n",
        "\n",
        "                # Select Orientation\n",
        "                # if (orientation not in [1,2,4,5]):\n",
        "                #     continue\n",
        "                \n",
        "                # Normalization\n",
        "                data_normed_1 = normalize_data(data_1)\n",
        "                # Update T_MAX\n",
        "                if T_MAX < np.array(data_1).shape[2]:\n",
        "                    T_MAX = np.array(data_1).shape[2]                \n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            # Save List\n",
        "            data.append(data_normed_1.tolist())\n",
        "            #data.append(data_1.tolist())\n",
        "            label.append(label_1_global)\n",
        "\n",
        "    # Zero-padding\n",
        "    data = zero_padding(data, T_MAX)\n",
        "    print(data.shape)\n",
        "    # Swap axes\n",
        "    data = np.swapaxes(np.swapaxes(data, 1, 3), 2, 3)   # [N,20,20',T_MAX]=>[N,T_MAX,20,20']\n",
        "    data = np.expand_dims(data, axis=-1)    # [N,T_MAX,20,20]=>[N,T_MAX,20,20,1]\n",
        "\n",
        "\n",
        "    # Convert label to ndarray\n",
        "    label = np.array(label)\n",
        "\n",
        "    # data(ndarray): [N,T_MAX,20,20,1], label(ndarray): [N,N_MOTION]\n",
        "    return data, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ho9QY_R7pI"
      },
      "source": [
        "# **Process and save data from each room into reusable numpy files**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1spF6x0eNnS"
      },
      "outputs": [],
      "source": [
        "#Selected gestures:\n",
        "ALL_MOTION = [1,2,3,4,6,9]\n",
        "N_MOTION = len(ALL_MOTION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmWJLoVGnvBv"
      },
      "outputs": [],
      "source": [
        "#Process and save Room 1 (only run first time, saves to OS/Drive as .npy)\n",
        "data_dir1 = 'Data/ROOM1/'\n",
        "data1, label1 = load_data(data_dir1, ALL_MOTION)\n",
        "np.save(\"data1.npy\",data1)\n",
        "np.save(\"label1.npy\",label1)\n",
        "print('\\nProcessed and saved dataset of ROOM 1, ' + str(label1.shape[0]) + ' samples, each sized ' + str(data1[0,:,:].shape) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUichDSQanSH"
      },
      "outputs": [],
      "source": [
        "#Process and save Room 2 (only run first time, saves to OS/Drive as .npy)\n",
        "data_dir2 = 'Data/ROOM2/'\n",
        "data2, label2 = load_data(data_dir2, ALL_MOTION)\n",
        "np.save(\"data2.npy\",data2)\n",
        "np.save(\"label2.npy\",label2)\n",
        "print('\\nProcessed and saved dataset of ROOM 2, ' + str(label2.shape[0]) + ' samples, each sized ' + str(data2[0,:,:].shape) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RRD_yGNxhKQ"
      },
      "outputs": [],
      "source": [
        "#Process and save Room 3 (only run first time, saves to OS/Drive as .npy)\n",
        "data_dir3 = 'Data/ROOM3/'\n",
        "data3, label3 = load_data(data_dir3, ALL_MOTION)\n",
        "np.save(\"data3.npy\",data3)\n",
        "np.save(\"label3.npy\",label3)\n",
        "print('\\nProcessed and saved dataset of ROOM 3, ' + str(label3.shape[0]) + ' samples, each sized ' + str(data3[0,:,:].shape) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taGeJa-n7jdt"
      },
      "outputs": [],
      "source": [
        "#Combine and save all data from all rooms into a single file (only run first time, saves to OS/Drive as .npy)\n",
        "data_all = np.concatenate((data1,data2),axis=0) \n",
        "label_all = np.concatenate((label1,label2),axis=0) \n",
        "data_all = np.concatenate((data_all,data3),axis=0) \n",
        "label_all = np.concatenate((label_all,label3),axis=0)\n",
        "\n",
        "np.save(\"data_all.npy\",data_all)\n",
        "np.save(\"label_all.npy\",label_all)\n",
        "print('\\nProcessed and saved dataset of all rooms, ' + str(label_all.shape[0]) + ' samples, each sized ' + str(data_all[0,:,:].shape) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g2Yxs_kSKSU"
      },
      "source": [
        "# **Load data from existing numpy files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvNR8zz3JoVH",
        "outputId": "f48bfef4-41b7-432d-97c2-d31cf048bd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded dataset of Room 1, 30717 samples, each sized (38, 20, 20, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Load room 1 from OS/Drive save\n",
        "data1 = np.load('data1.npy')\n",
        "label1 = np.load('label1.npy')\n",
        "print('\\nLoaded dataset of Room 1, ' + str(label1.shape[0]) + ' samples, each sized ' + str(data1[0,:,:].shape) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSV-pgJILHtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c6ab70-fb33-487c-da84-cf1d83c90746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded dataset of Room 2, 5300 samples, each sized (29, 20, 20, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Load room 2 from OS/Drive save\n",
        "data2 = np.load('data2.npy')\n",
        "label2 = np.load('label2.npy')\n",
        "print('\\nLoaded dataset of Room 2, ' + str(label2.shape[0]) + ' samples, each sized ' + str(data2[0,:,:].shape) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIpKGgzwLHDI",
        "outputId": "eb33753a-a28d-4a57-a266-5644994b3297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded dataset of Room 3, 2995 samples, each sized (24, 20, 20, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Load room 3 from OS/Drive save\n",
        "data3 = np.load('data3.npy')\n",
        "label3 = np.load('label3.npy')\n",
        "print('\\nLoaded dataset of Room 3, ' + str(label3.shape[0]) + ' samples, each sized ' + str(data3[0,:,:].shape) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYRFjFCXRsJl",
        "outputId": "5321521a-e933-4fc4-d8b0-2348abd5d6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded dataset of all rooms, 41963 samples, each sized (38, 20, 20, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Load combined file from OS/Drive save\n",
        "data_all= np.load('data_all.npy')\n",
        "label_all= np.load('label_all.npy') \n",
        "print('\\nLoaded dataset of all rooms, ' + str(label_all.shape[0]) + ' samples, each sized ' + str(data_all[0,:,:].shape) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYi7IhnHSbj1"
      },
      "source": [
        "# **Training and Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nej6X0JsUkeq"
      },
      "source": [
        "**Data configuration (select cell depending on experiment type)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtZ9HLlon71k"
      },
      "outputs": [],
      "source": [
        "#SELECT CROSS-DOMAIN (adjust individually)\n",
        "\n",
        "#Train on:\n",
        "data_train, label_train = data1, label1\n",
        "\n",
        "#Test on:\n",
        "data_test, label_test = data3, label3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as6QXPoCogB1"
      },
      "outputs": [],
      "source": [
        "#SELECT IN-DOMAIN (adjust individually)\n",
        "#Train and test on:\n",
        "data = data2\n",
        "label = label2\n",
        "fraction_for_test = 0.1\n",
        "\n",
        "#Optional: randomly select specific number of samples from data selected (e.g. limit to 3000 samples)\n",
        "N= 0\n",
        "\n",
        "if N!=0:\n",
        "  index = random.sample(range(0, N), N-1)\n",
        "  data=data[index]\n",
        "  label=label[index]\n",
        "\n",
        "#print(data.shape)\n",
        "#print(label.shape)\n",
        "\n",
        "\n",
        "#Split train and test randomly with fraction specified  (data, label, test_size=fraction_for_test)\n",
        "[data_train, data_test, label_train, label_test] = train_test_split(data,label,test_size=fraction_for_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7_5Cl4bUwcX"
      },
      "source": [
        "**Initialize MiniRocket instance, generate features, and train classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ban2jd_UdDH"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "data_train= np.array(data_train).astype('float32')\n",
        "data_test= np.array(data_test).astype('float32')\n",
        "\n",
        "#Flatten X and Y parameters (20x20) into single dimension (400)\n",
        "data_train = data_train.reshape((data_train.shape[0],data_train.shape[1],data_train.shape[2]*data_train.shape[3]))\n",
        "data_test = data_test.reshape((data_test.shape[0],data_test.shape[1],data_test.shape[2]*data_test.shape[3]))\n",
        "data_train = data_train.swapaxes(1,2)\n",
        "data_test = data_test.swapaxes(1,2)\n",
        "\n",
        "#print(\"Input shape:\", data_train.shape)\n",
        "\n",
        "#Initialize a MiniRocket instance\n",
        "minirocket_multi = MiniRocketMultivariate()\n",
        "\n",
        "\n",
        "#Shape passed should be (N, 400, T_MAX) where N is number of samples, 400 is flattened X/Y of BVP, and T_MAX is the number of time recordings per sample\n",
        "start_time_train = time.time()\n",
        "\n",
        "minirocket_multi = minirocket_multi.fit(data_train)\n",
        "X_train_transform = minirocket_multi.transform(data_train)\n",
        "f_mean = X_train_transform.mean(0)\n",
        "f_std = X_train_transform.std(0) + 1e-8\n",
        "X_train_transform = (X_train_transform - f_mean) / f_std\n",
        "\n",
        "classifier = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10), normalize = True)\n",
        "classifier.fit(X_train_transform, label_train)\n",
        "\n",
        "end_time_train = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVQt9ceJU7Zb"
      },
      "source": [
        "**Evaluate classification accuracy and time complexity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-furBnDYyys"
      },
      "outputs": [],
      "source": [
        "#Overall accuracy\n",
        "start_time_infer= time.time()\n",
        "\n",
        "X_test_transform = minirocket_multi.transform(data_test)\n",
        "X_test_transform = (X_test_transform - f_mean) / f_std\n",
        "score = classifier.score(X_test_transform, label_test)\n",
        "\n",
        "end_time_infer = time.time()\n",
        "\n",
        "#Generate confusion matrix\n",
        "label_pred = classifier.predict(X_test_transform)\n",
        "print(set(label_pred.flatten()))\n",
        "cm = confusion_matrix(label_test, label_pred)\n",
        "print(cm)\n",
        "\n",
        "\n",
        "print('\\nAverage Accuracy: %f' %(score))\n",
        "\n",
        "#Compute accuracy by gesture\n",
        "for i in range(0,len(cm)):\n",
        "  avg= cm[i][i]/ np.sum(cm[i])\n",
        "  print('Gesture %d: %f'% (ALL_MOTION[i],avg) )\n",
        "\n",
        "#Report time to train and infer\n",
        "train_time = end_time_train - start_time_train\n",
        "infer_time = end_time_infer - start_time_infer\n",
        "print(\"\\nTraining on %d samples took %f seconds\" %(data_train.shape[0], train_time) )\n",
        "print(\"Inference of %d samples took %f seconds\" %(data_test.shape[0], infer_time) )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "MiniRocket_Implementation_Version_2 (2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}